# Recommender System

A recommendation system that suggests SHL assessments based on job descriptions using sentence embeddings, LLMs (Gemini), and cosine similarity. Built with a FastAPI backend and Streamlit frontend.

ðŸ“¦ Features
Web Scraping: Collects SHL test info (name, duration, type, job level, etc.)
Preprocessing: Cleans data and generates SBERT embeddings (all-MiniLM-L6-v2)
LLM Parsing: Uses Gemini to extract filters from natural language
Semantic Recommendation: Ranks relevant tests using cosine similarity
Evaluation: Computes Recall@K and MAP@K on sample queries
Deployment: FastAPI API + Streamlit UI

ðŸ§° Tech Stack
Backend: FastAPI, Uvicorn
Frontend: Streamlit
LLM: Gemini via Google Generative AI SDK
NLP: SentenceTransformers
Others: LangChain, dotenv, Selenium, BeautifulSoup

ðŸš€ Quickstart
# Install dependencies
pip install -r requirements.txt
# Set your Gemini API key
export GEMINI_API_KEY=your_api_key
# Run preprocessing
python data_preprocessing.py
# Launch frontend
streamlit run src/frontend.py

ðŸ—‚ Project Structure

â”œâ”€â”€ data/                         # SHL data & evaluation queries
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ backend.py                # FastAPI backend
â”‚   â”œâ”€â”€ frontend.py               # Streamlit UI
â”‚   â”œâ”€â”€ recommender.py            # Cosine similarity recommendation logic
â”‚   â”œâ”€â”€ llm_processor.py          # Gemini-powered query parsing
â”‚   â”œâ”€â”€ data_preprocessing.py     # Cleans + embeds SHL data
â”‚   â””â”€â”€ evaluation.py             # Evaluation metrics
â”œâ”€â”€ web/
â”‚   â””â”€â”€ web_scraping.ipynb        # Web scraping SHL assessments
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


